{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from colorama import Fore, Style\n",
    "\n",
    "def extract_data_from_txt(path):\n",
    "    with open(path, 'r') as file:\n",
    "        content = file.read()\n",
    "        lines = content.splitlines()  \n",
    "        \n",
    "        # RF EMP-STD\n",
    "        line_5 = lines[4]  \n",
    "        rf_emp_std = re.search(r\"RF EMP-STD:\\s+(\\d+\\.\\d+)\", line_5)\n",
    "\n",
    "        # WB EMP-STD\n",
    "        line_6 = lines[3]  \n",
    "        wb_emp_std = re.search(r\"WB EMP-STD:\\s+(\\d+\\.\\d+)\", line_6)\n",
    "\n",
    "        # WB MSE\n",
    "        line_40 = lines[40]  \n",
    "        wb_mse = re.search(r\"WB MSE IPCW:\\s+(\\d+\\.\\d+)\", line_40)\n",
    "\n",
    "        # RF MSE\n",
    "        line_41 = lines[41]  \n",
    "        rf_mse = re.search(r\"RF MSE IPCW:\\s+(\\d+\\.\\d+)\", line_41)\n",
    "\n",
    "        # Events und Censored\n",
    "        events_prop = re.search(r\"Events:\\s+(\\d+\\.\\d+)\\s+%\", content)\n",
    "        censored_prop = re.search(r\"Censored:\\s+(\\d+\\.\\d+)\\s+%\", content)\n",
    "\n",
    "        # IJK \n",
    "        ijk_std = re.search(r\"IJK STD \\(for RF\\) Mean-est\\s+:\\s+(\\d+\\.\\d+)\", content)\n",
    "        ijk_std_rel_error = re.search(r\"rel\\. Abweichung zu emp\\. std ([\\-\\d\\.]+) %\", content)\n",
    "        ijk_std_cv = re.search(r\"std\\. des schätzers (\\d+\\.\\d+)\", content)\n",
    "        \n",
    "        # IJK biased\n",
    "        line_11 = lines[10] \n",
    "        ijk_biased_std = re.search(r\"IJK STD - biased \\(for RF\\) Mean-est\\s*:\\s*(\\d+\\.\\d+)\", line_11)\n",
    "        line_12 = lines[11]  \n",
    "        ijk_biased_std_rel_error = re.search(r\"rel\\. Abweichung zu emp\\. std ([\\-\\d\\.]+) %\", line_12)\n",
    "        line_13 = lines[12] \n",
    "        ijk_biased_std_cv = re.search(r\"std\\. des schätzers\\s+(\\d+\\.\\d+)\", line_13)\n",
    "        \n",
    "        # JK-AB \n",
    "        jkab_std = re.search(r\"JK-AB\\(un-weighted\\) STD \\(for RF\\) Mean-est:\\s+(\\d+\\.\\d+)\", content)\n",
    "        line_16 = lines[15] \n",
    "        jkab_std_rel_error = re.search(r\"rel\\. Abweichung zu emp\\. std ([\\-\\d\\.]+) %\", line_16)\n",
    "        line_17 = lines[16]\n",
    "        jkab_std_cv= re.search(r\"std\\. des schätzers (\\d+\\.\\d+)\", line_17)\n",
    "\n",
    "        # Prediction Results\n",
    "        true_y = re.search(r\"True Y:\\s+(\\d+\\.\\d+)\", content)\n",
    "        rf_y_pred = re.search(r\"RF Y_pred:\\s+(\\d+\\.\\d+)\", content)\n",
    "        wb_y_pred = re.search(r\"WB Y_pred:\\s+(\\d+\\.\\d+)\", content)\n",
    "\n",
    "        # Erstellen eines Dictionaries mit den extrahierten Daten\n",
    "        data = {\n",
    "            'censored_proportion': round(float(censored_prop.group(1))/100,1) if censored_prop else None,\n",
    "            'events_proportion': round(float(events_prop.group(1))/100,2) if events_prop else None,\n",
    "            'ijk_std': float(ijk_std.group(1)) if ijk_std else None,\n",
    "            'ijk_std_rel_error(%)': float(ijk_std_rel_error.group(1)) if ijk_std_rel_error else None,\n",
    "            'ijk_std_cv': float(ijk_std_cv.group(1))/float(ijk_std.group(1)) if ijk_std_cv and ijk_std else None,\n",
    "            'jkab_std': float(jkab_std.group(1)) if jkab_std else None,\n",
    "            'jkab_std_rel_error(%)': float(jkab_std_rel_error.group(1)) if jkab_std_rel_error else None,\n",
    "            'jkab_std_cv': float(jkab_std_cv.group(1))/float(jkab_std.group(1)) if jkab_std_cv and jkab_std else None,\n",
    "            'True_Y': float(true_y.group(1)) if true_y else None,\n",
    "            'RF_Y_pred': float(rf_y_pred.group(1)) if rf_y_pred else None,\n",
    "            'WB_Y_pred': float(wb_y_pred.group(1)) if wb_y_pred else None,\n",
    "            'wb_emp_std': float(wb_emp_std.group(1)) if wb_emp_std else None,\n",
    "            'rf_emp_std': float(rf_emp_std.group(1)) if rf_emp_std else None,\n",
    "            'ijk_biased_std': float(ijk_biased_std.group(1)) if ijk_biased_std else None,\n",
    "            'ijk_biased_std_rel_error(%)': float(ijk_biased_std_rel_error.group(1)) if ijk_biased_std_rel_error else None,\n",
    "            'ijk_biased_std_cv': float(ijk_biased_std_cv.group(1))/float(ijk_biased_std.group(1)) if ijk_biased_std_cv and ijk_biased_std else None,\n",
    "            'wb_mse': float(wb_mse.group(1)) if wb_mse else None,\n",
    "            'rf_mse': float(rf_mse.group(1)) if rf_mse else None\n",
    "        }\n",
    "        return data\n",
    "\n",
    "\n",
    "def process_folders(main_folder, save_path_for_csv):\n",
    "    data_list = []\n",
    "\n",
    "    for folder_name in os.listdir(main_folder):\n",
    "        folder_path = os.path.join(main_folder, folder_name)\n",
    "\n",
    "        if os.path.isdir(folder_path):\n",
    "            result_file_path = os.path.join(folder_path, 'results.txt')\n",
    "\n",
    "            if os.path.exists(result_file_path):\n",
    "                data = extract_data_from_txt(result_file_path)\n",
    "                data_list.append(data)\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df_sorted = df.sort_values(by=['censored_proportion', 'events_proportion'], ascending=[True, True])\n",
    "    df_sorted['events_bin'] = ['EE1', 'EE2', 'EE3', 'EE4', \n",
    "                               'EE1', 'EE2', 'EE3', 'EE4',\n",
    "                               'EE1', 'EE2', 'EE3', 'EE4',\n",
    "                               'EE1', 'EE2', 'EE3', 'EE4']\n",
    "    df_sorted.to_csv(os.path.join(save_path_for_csv, 'results_summary.csv'), index=False)\n",
    "\n",
    "    return df_sorted\n",
    "\n",
    "\n",
    "def save_plot(save_path, data, n, B, shape):\n",
    "    \n",
    "    censored_values = sorted(data['censored_proportion'].unique())\n",
    "    events_bins = sorted(data['events_bin'].unique())\n",
    "\n",
    "    censored_indices = {value: idx for idx, value in enumerate(censored_values)}\n",
    "    events_indices = {label: idx for idx, label in enumerate(events_bins)}\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(16, 12), sharex=True, sharey=True)\n",
    "\n",
    "    # Listen zum Sammeln der Handles und Labels\n",
    "    handles = []\n",
    "    labels = []\n",
    "    legend_added = False  # Flag, um sicherzustellen, dass die Legende nur einmal hinzugefügt wird\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        censored = row['censored_proportion']\n",
    "        event_bin = row['events_bin']\n",
    "        True_Y = row['True_Y']\n",
    "        RF_Y_pred = row['RF_Y_pred']\n",
    "        WB_Y_pred = row['WB_Y_pred']\n",
    "        wb_mse = row['wb_mse']\n",
    "        rf_mse = row['rf_mse']\n",
    "        \n",
    "        row_idx = censored_indices[censored]\n",
    "        col_idx = events_indices[event_bin]\n",
    "        ax = axes[row_idx, col_idx]\n",
    "        \n",
    "        rf_emp_std = row['rf_emp_std']\n",
    "        wb_emp_std = row['wb_emp_std']\n",
    "        \n",
    "        error_rf = 1.96 * rf_emp_std\n",
    "        error_wb = 1.96 * wb_emp_std\n",
    "        \n",
    "        # Plot mit Labels für die Legende\n",
    "        dtbd_plot = ax.errorbar(0, RF_Y_pred, yerr=error_rf, fmt='o', color='black', ecolor='black',\n",
    "                                capsize=5, label='DTBD prediction')\n",
    "        waft_plot = ax.errorbar(1., WB_Y_pred, yerr=error_wb, fmt='o', color='darkgreen', ecolor='black',\n",
    "                                capsize=5, label='W-AFT prediction')\n",
    "        true_y_plot = ax.axhline(y=True_Y, color='red', linestyle='--', linewidth=2, label='True Survival Probability')\n",
    "        \n",
    "        ax.set_ylim(0.5, 1)\n",
    "        ax.set_title(f'[ Event Prop: {row[\"events_proportion\"]} ]', fontsize=10)\n",
    "\n",
    "        if col_idx == 0:\n",
    "            ax.set_ylabel(f'[ Cens Prop: {censored} ] \\n Survival Probability', fontsize=10)\n",
    "        \n",
    "        fz = 12\n",
    "        aaa = 0.05\n",
    "        \n",
    "        # Geänderte Textzeilen ohne Überstrich\n",
    "        ax.text(0.12, 0.2-aaa, 'W-AFT IPCW MSE:', fontsize=fz, transform=ax.transAxes)\n",
    "        ax.text(0.55, 0.2-aaa, wb_mse, fontsize=fz, transform=ax.transAxes)\n",
    "\n",
    "        ax.text(0.12, 0.1-aaa, 'DTBC IPCW MSE:', fontsize=fz, transform=ax.transAxes)\n",
    "        ax.text(0.55, 0.1-aaa, rf_mse, fontsize=fz, transform=ax.transAxes)\n",
    "\n",
    "        ax.grid(True, linestyle='--', alpha=1.)\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "        # Sammle Handles und Labels einmalig\n",
    "        if not legend_added:\n",
    "            handles.extend([dtbd_plot, waft_plot, true_y_plot])\n",
    "            labels.extend(['DTBC prediction', 'W-AFT prediction', 'True Survival Probability'])\n",
    "            legend_added = True  # Stelle sicher, dass dies nur einmal geschieht\n",
    "\n",
    "    # Leere Subplots ausblenden\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            ax = axes[i, j]\n",
    "            # Überprüfen, ob der Subplot Daten enthält\n",
    "            if not (ax.lines or ax.collections):\n",
    "                ax.axis('off')\n",
    "\n",
    "    # Füge eine figure-weite Legende hinzu ohne Titel und mit Rahmen\n",
    "    fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 0.98), ncol=3, frameon=True,edgecolor='black', fontsize=12)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Anpassung des Layouts, um Platz für die Legende zu schaffen\n",
    "    fig.savefig(os.path.join(save_path, f'n_train{n}_B_{B}_shape_{shape}.png'), dpi=300)\n",
    "    plt.close(fig)  # Schließt die Figur, um Speicher freizugeben\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = [500,1000,2000,4000]\n",
    "n = [499,999,1999,3999]\n",
    "\n",
    "\n",
    "save_ordner_name = '2_plot_sims_model'   ######\n",
    "\n",
    "save_path_shape_1 = f'C:\\\\Users\\\\rehan\\\\meine_repos\\\\Masterarbeit\\\\Chapter 3\\\\{save_ordner_name}\\\\shape1'\n",
    "save_path_shape_1_5 = f'C:\\\\Users\\\\rehan\\\\meine_repos\\\\Masterarbeit\\\\Chapter 3\\\\{save_ordner_name}\\\\shape1_5'\n",
    "\n",
    "if not os.path.exists(save_path_shape_1):\n",
    "    os.makedirs(save_path_shape_1)\n",
    "if not os.path.exists(save_path_shape_1_5):\n",
    "    os.makedirs(save_path_shape_1_5)\n",
    "\n",
    "for n_i in n:\n",
    "    for b in B:     \n",
    "        path_1 =   f'C:\\\\Users\\\\rehan\\\\meine_Repos\\\\Masterarbeit\\\\Chapter 3\\\\1_sims\\\\sim_shape_1___B{b}\\\\{n_i}'\n",
    "        path_1_5 = f'C:\\\\Users\\\\rehan\\\\meine_Repos\\\\Masterarbeit\\\\Chapter 3\\\\1_sims\\\\sim_shape_1_5_B{b}\\\\{n_i}'\n",
    "        \n",
    "        results_df = process_folders(path_1,path_1)\n",
    "        results_df_1_5 = process_folders(path_1_5,path_1_5)\n",
    "\n",
    "        save_plot(save_path_shape_1, results_df, n_i, b, '1')\n",
    "        save_plot(save_path_shape_1_5, results_df_1_5, n_i, b, '1_5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Master-Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
